{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ixKaNeVV1g"
      },
      "source": [
        "# <u><center>Naive Bayes Algorithms</center></u>\n",
        "\n",
        "\n",
        "Naive Bayes models is one of the simplest supervised learning algorithms. Naive Bayes classifier is the fast, accurate and reliable algorithm. Naive Bayes classifiers have high accuracy and speed on large datasets.\n",
        "\n",
        "As the name suggested Naive Bayes is based on **Bayes Theorem**. It assumes that the effect of a particular feature in a class is independent of other features. For example, a loan applicant is desirable or not depending on his/her income, previous loan and transaction history, age, and location. Even if these features are interdependent, these features are still considered independently. This assumption simplifies computation, and that's why it is considered as **naive.**\n",
        "\n",
        "So here it is important to know what is Bayes theorem.\n",
        "Bayes’ Theorem provides a way that we can calculate the probability of a piece of data belonging to a given class, given our prior knowledge. Bayes’ Theorem is stated as:\n",
        "\n",
        "\n",
        "**P(class|data) = (P(data|class) * P(class)) / P(data)**\n",
        "\n",
        "Where P(class|data) is the probability of class given the provided data.\n",
        "\n",
        "    Lets get started with Naive Bayes. Here we will use data with collection of SMS messages. It contains 5572 records of different messages together with 747 spam messages.\n",
        "\n",
        "`Use case:** You need to classify if a message is spam or not.`\n",
        "\n",
        "Note : Download the dataset from your canvas account\n",
        "\n",
        "Reference documentation: https://scikit-learn.org/stable/modules/naive_bayes.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "8gBFkAaoVV1j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sklearn.metrics\n",
        "import matplotlib as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8kHkHN-VV1l"
      },
      "source": [
        "### Preparing Data\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WiW5HeAxVV1l"
      },
      "outputs": [],
      "source": [
        "#Read SMSSpamCollection dataset\n",
        "docs = pd.read_csv('SMSSpamCollection.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CKm0Ub5CVV1l",
        "outputId": "c087d0d1-1dfc-4e8f-cf60-f0b94622730b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Class                                                sms\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-85717eb4-2c82-4ebf-b2ae-85853b2faa9a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>sms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85717eb4-2c82-4ebf-b2ae-85853b2faa9a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-85717eb4-2c82-4ebf-b2ae-85853b2faa9a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-85717eb4-2c82-4ebf-b2ae-85853b2faa9a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-879cf15a-05d3-4f22-84e1-062cac573cd1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-879cf15a-05d3-4f22-84e1-062cac573cd1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-879cf15a-05d3-4f22-84e1-062cac573cd1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#print first 5 records\n",
        "docs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LcFsNVpNVV1m",
        "outputId": "b43cb212-9801-4563-d663-9e7edafe9b92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ham     4825\n",
            "spam     747\n",
            "Name: Class, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# counting spam and ham instances\n",
        "ham_spam= docs.Class.value_counts()\n",
        "\n",
        "#print ham_spam\n",
        "print(ham_spam)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "UBjR3c9JVV1n",
        "outputId": "b3ace2c0-2448-4a71-d7f6-4662901e9072",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spam % is 13.406317300789663\n"
          ]
        }
      ],
      "source": [
        "# Assuming ham_spam is a Series containing ham and spam counts\n",
        "# For example: ham_spam = pd.Series([500, 200]) where 500 is ham count and 200 is spam count\n",
        "\n",
        "# Calculate the percentage of spam messages\n",
        "spam_percentage = (ham_spam[1] / (ham_spam[0] + ham_spam[1])) * 100\n",
        "\n",
        "# Print the spam percentage\n",
        "print(\"Spam % is\", spam_percentage)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K95943n4VV1n",
        "outputId": "8a764c4e-2842-476f-b374-e6b899389465",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Class                                                sms  label\n",
              "0   ham  Go until jurong point, crazy.. Available only ...      0\n",
              "1   ham                      Ok lar... Joking wif u oni...      0\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
              "3   ham  U dun say so early hor... U c already then say...      0\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9984de78-a620-47a7-8df6-3547bf6a00de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>sms</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9984de78-a620-47a7-8df6-3547bf6a00de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9984de78-a620-47a7-8df6-3547bf6a00de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9984de78-a620-47a7-8df6-3547bf6a00de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c40f52d3-7458-4380-96f2-51d10b46bd58\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c40f52d3-7458-4380-96f2-51d10b46bd58')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c40f52d3-7458-4380-96f2-51d10b46bd58 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# mapping a column labels to ham as 0 and spam as 1\n",
        "docs['label'] = docs.Class.map({'ham':0,'spam':1})\n",
        "#print last 5 records of dataset\n",
        "docs.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dCwl4KWrVV1o",
        "outputId": "cac9ce9d-a070-4cf3-af7f-0c29469f77b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5572,)\n",
            "(5572,)\n"
          ]
        }
      ],
      "source": [
        "#Fetch all features\n",
        "X=docs.sms\n",
        "\n",
        "#Fetch label\n",
        "y=docs.label\n",
        "\n",
        "\n",
        "#print shape of X and y\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "VoJf7LdQVV1o"
      },
      "outputs": [],
      "source": [
        "# import train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitting into test and train with random state as 1 and test size as 25%\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxHuwbsHVV1p"
      },
      "source": [
        "## Naive Bayes in scikit-learn\n",
        "\n",
        "scikit-learn implements three naive Bayes variants based on the same number of different probabilistic distributions:\n",
        "1. **Bernoulli :** This is a binary distribution useful when a feature can be present or absent.\n",
        "2. **multinomial :**This is a discrete distribution used whenever a feature must be represented by a whole number (for example, in natural language processing, it can be the frequency of a term)\n",
        "3.**Gaussian :** This is a continuous distribution characterized by its mean and variance.\n",
        "\n",
        "So here you think, which variant will you be using for your problem statement\n",
        "\n",
        "# **`WATCH ALL VIDEOS IN THE PORTAL`**\n",
        "## **`Watch Video 1 : NaiveBayes Intro`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hqxcqMZrVV1p",
        "outputId": "d8d26606-059f-454d-8894-1b56c35c62d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710     4mths half price Orange line rental & latest c...\n",
              "3740                           Did you stitch his trouser\n",
              "2711    Hope you enjoyed your new content. text stop t...\n",
              "3155    Not heard from U4 a while. Call 4 rude chat pr...\n",
              "3748    Ü neva tell me how i noe... I'm not at home in...\n",
              "Name: sms, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# print X_train first 5 records\n",
        "X_train.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pXz-HTOVV1q"
      },
      "source": [
        "### vectorization of words.\n",
        "\n",
        "<p style='text-align: right;'> 20 points </p>\n",
        "\n",
        "\n",
        "Here you can see that your features are in form of sequence of words or you can say sentences. Now to feed this information into our algorithm we need make it in form of numbers.\n",
        "\n",
        "But how?\n",
        "\n",
        "Sklearn has awesome library to extract features from text. This library is called CountVectorizer: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "Imagine breaking X in individual words and putting them all in a bag. Then we pick all the unique words from the bag one by one and make a dictionary of unique words.\n",
        "\n",
        "This is called **vectorization of words**. We have the class ```CountVectorizer()``` in scikit learn to vectorize the words. Let us first see it in action before explaining it further.\n",
        "\n",
        "```Countvectorizer()``` will convert the documents into a set of unique words alphabetically sorted and indexed.\n",
        "**Stop Words**\n",
        "\n",
        "We can see a few trivial words such as  'and','is','of', etc. These words don't really make any difference in classyfying a document. These are called 'stop words'. So we would like to get rid of them.\n",
        "\n",
        "We can remove them by passing a parameter stop_words='english' while instantiating ```Countvectorizer()```\n",
        "\n",
        "\n",
        "**Reference video:**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 2: Text Analytics(Count Vectorizer)`**"
      ],
      "metadata": {
        "id": "BY1iCYGym9oQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H0sxWrsnVV1r",
        "outputId": "e6b6ccbd-d18a-47c5-d2dc-74bf375dfe04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(stop_words='english')"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=&#x27;english&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# import CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#Instantiate CountVectorizer with stop_words\n",
        "vect = CountVectorizer(stop_words='english')\n",
        "\n",
        "\n",
        "# fit vect on your feature text (X_train)\n",
        "vect.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yipEeQx-VV1s"
      },
      "source": [
        "Here ```vect``` is an object of class ```CountVectorizer()```. This has a method called  ```fit()``` which converts a corpus of documents into a vector of unique words as shown below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4MwPQIiVV1s"
      },
      "source": [
        "Bam! So you have fit the features with X_train. Remember its not tranformed into vectors yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lnrvJujlVV1s",
        "outputId": "371d299b-3d90-458b-88e0-f1666e479b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'4mths': 509,\n",
              " 'half': 3089,\n",
              " 'price': 5027,\n",
              " 'orange': 4626,\n",
              " 'line': 3852,\n",
              " 'rental': 5310,\n",
              " 'latest': 3763,\n",
              " 'camera': 1527,\n",
              " 'phones': 4822,\n",
              " 'free': 2780,\n",
              " 'phone': 4818,\n",
              " '11mths': 264,\n",
              " 'mobilesdirect': 4248,\n",
              " '08000938767': 50,\n",
              " 'update': 6673,\n",
              " 'or2stoptxt': 4624,\n",
              " 'cs': 1971,\n",
              " 'did': 2169,\n",
              " 'stitch': 6028,\n",
              " 'trouser': 6545,\n",
              " 'hope': 3260,\n",
              " 'enjoyed': 2436,\n",
              " 'new': 4442,\n",
              " 'content': 1867,\n",
              " 'text': 6321,\n",
              " 'stop': 6038,\n",
              " '61610': 563,\n",
              " 'unsubscribe': 6665,\n",
              " 'help': 3180,\n",
              " '08712400602450p': 98,\n",
              " 'provided': 5089,\n",
              " 'tones2you': 6473,\n",
              " 'uk': 6614,\n",
              " 'heard': 3159,\n",
              " 'u4': 6608,\n",
              " 'rude': 5443,\n",
              " 'chat': 1643,\n",
              " 'private': 5040,\n",
              " '01223585334': 5,\n",
              " 'cum': 1989,\n",
              " 'wan': 6852,\n",
              " '2c': 374,\n",
              " 'pics': 4837,\n",
              " 'gettin': 2913,\n",
              " 'shagged': 5628,\n",
              " 'pix': 4858,\n",
              " '8552': 660,\n",
              " '2end': 378,\n",
              " 'send': 5590,\n",
              " 'sam': 5487,\n",
              " 'xxx': 7127,\n",
              " 'neva': 4438,\n",
              " 'tell': 6289,\n",
              " 'noe': 4477,\n",
              " 'home': 3244,\n",
              " 'da': 2015,\n",
              " 'aft': 826,\n",
              " 'wat': 6876,\n",
              " 'wiskey': 7012,\n",
              " 'brandy': 1389,\n",
              " 'rum': 5450,\n",
              " 'gin': 2927,\n",
              " 'beer': 1209,\n",
              " 'vodka': 6798,\n",
              " 'scotch': 5535,\n",
              " 'shampain': 5637,\n",
              " 'wine': 6993,\n",
              " 'kudi': 3715,\n",
              " 'yarasu': 7142,\n",
              " 'dhina': 2156,\n",
              " 'vaazhthukkal': 6720,\n",
              " 'seeking': 5573,\n",
              " 'lady': 3732,\n",
              " 'street': 6056,\n",
              " 'freak': 2776,\n",
              " 'sheets': 5649,\n",
              " 'lol': 3910,\n",
              " 'drunkard': 2327,\n",
              " 'just': 3623,\n",
              " 'doing': 2259,\n",
              " 'hair': 3085,\n",
              " 'moment': 4265,\n",
              " 'yeah': 7149,\n",
              " 'tonight': 6475,\n",
              " 'wats': 6887,\n",
              " 'plan': 4867,\n",
              " 'turning': 6579,\n",
              " 'moms': 4267,\n",
              " 'telling': 6290,\n",
              " 'cancer': 1535,\n",
              " 'sister': 5745,\n",
              " 'won': 7041,\n",
              " 'calling': 1519,\n",
              " 'hurts': 3323,\n",
              " 'talk': 6234,\n",
              " 'love': 3953,\n",
              " 'coming': 1800,\n",
              " 'dinner': 2193,\n",
              " 'rite': 5396,\n",
              " 'dad': 2018,\n",
              " 'ask': 1032,\n",
              " 'confirm': 1843,\n",
              " 'wif': 6977,\n",
              " 'ah': 842,\n",
              " 'poor': 4931,\n",
              " 'baby': 1121,\n",
              " 'urfeeling': 6687,\n",
              " 'bettersn': 1243,\n",
              " 'luv': 3988,\n",
              " 'probthat': 5052,\n",
              " 'overdose': 4667,\n",
              " 'work': 7058,\n",
              " 'hey': 3198,\n",
              " 'careful': 1556,\n",
              " 'spk': 5938,\n",
              " 'sn': 5822,\n",
              " 'lots': 3942,\n",
              " 'lovejen': 3955,\n",
              " 'gam': 2856,\n",
              " 'gone': 2968,\n",
              " 'outstanding': 4664,\n",
              " 'innings': 3438,\n",
              " 'nice': 4453,\n",
              " 'working': 7062,\n",
              " 'haha': 3081,\n",
              " 'kidding': 3672,\n",
              " 'papa': 4705,\n",
              " 'needs': 4417,\n",
              " 'drugs': 2325,\n",
              " 'chief': 1677,\n",
              " 'bell': 1223,\n",
              " 'need': 4412,\n",
              " 'royal': 5432,\n",
              " 'visit': 6789,\n",
              " '1st': 324,\n",
              " 'june': 3618,\n",
              " 'ugh': 6610,\n",
              " 'long': 3917,\n",
              " 'day': 2054,\n",
              " 'exhausted': 2523,\n",
              " 'want': 6857,\n",
              " 'cuddle': 1984,\n",
              " 'nap': 4381,\n",
              " 'awesome': 1103,\n",
              " 'time': 6418,\n",
              " 'like': 3840,\n",
              " 'lt': 3974,\n",
              " 'gt': 3044,\n",
              " 'll': 3887,\n",
              " 'details': 2143,\n",
              " 'wee': 6916,\n",
              " 'bit': 1277,\n",
              " 'ok': 4578,\n",
              " 'lor': 3932,\n",
              " 'thk': 6376,\n",
              " 'tickets': 6407,\n",
              " 'cos': 1901,\n",
              " 'quite': 5149,\n",
              " 'late': 3760,\n",
              " 'look': 3921,\n",
              " 'ur': 6684,\n",
              " 'frens': 2791,\n",
              " 'darren': 2041,\n",
              " 'dont': 2269,\n",
              " 'know': 3700,\n",
              " 'bring': 1414,\n",
              " 'food': 2730,\n",
              " 'reason': 5224,\n",
              " 've': 6744,\n",
              " 'spoken': 5948,\n",
              " 'year': 7150,\n",
              " 'anyways': 947,\n",
              " 'great': 3020,\n",
              " 'week': 6918,\n",
              " 'best': 1237,\n",
              " 'exam': 2511,\n",
              " 'make': 4042,\n",
              " 'fucks': 2825,\n",
              " 'sake': 5476,\n",
              " 'yes': 7160,\n",
              " 'place': 4862,\n",
              " 'town': 6504,\n",
              " 'meet': 4130,\n",
              " 'exciting': 2515,\n",
              " 'adult': 806,\n",
              " 'singles': 5739,\n",
              " 'txt': 6590,\n",
              " '86688': 664,\n",
              " '150p': 293,\n",
              " 'msg': 4315,\n",
              " 'man': 4052,\n",
              " 'print': 5035,\n",
              " 'outs': 4660,\n",
              " 'room': 5418,\n",
              " 'think': 6368,\n",
              " 'saying': 5517,\n",
              " 'clearly': 1734,\n",
              " 'leave': 3793,\n",
              " 'come': 1794,\n",
              " 'st': 5972,\n",
              " 'andre': 912,\n",
              " 'virgil': 6783,\n",
              " 'cream': 1947,\n",
              " 'yoyyooo': 7179,\n",
              " 'change': 1623,\n",
              " 'permissions': 4789,\n",
              " 'drive': 2313,\n",
              " 'mac': 4013,\n",
              " 'usb': 6699,\n",
              " 'flash': 2692,\n",
              " 'sunshine': 6148,\n",
              " 'quiz': 5151,\n",
              " 'wkly': 7024,\n",
              " 'win': 6987,\n",
              " 'sony': 5865,\n",
              " 'dvd': 2350,\n",
              " 'player': 4875,\n",
              " 'country': 1914,\n",
              " 'algarve': 875,\n",
              " 'ansr': 927,\n",
              " '82277': 637,\n",
              " '50': 520,\n",
              " 'sp': 5898,\n",
              " 'tyrone': 6606,\n",
              " 'dear': 2066,\n",
              " 'th': 6333,\n",
              " 'birthday': 1275,\n",
              " 'loving': 3963,\n",
              " 'gopalettan': 2984,\n",
              " 'planning': 4871,\n",
              " 'small': 5796,\n",
              " 'gift': 2921,\n",
              " 'participate': 4724,\n",
              " 'welcome': 6933,\n",
              " 'contact': 1863,\n",
              " 'admin': 793,\n",
              " 'team': 6274,\n",
              " 'class': 1724,\n",
              " 'hours': 3282,\n",
              " 'sorry': 5877,\n",
              " 'okay': 4579,\n",
              " 'wait': 6834,\n",
              " 'rushing': 5458,\n",
              " 'school': 5527,\n",
              " 'rush': 5457,\n",
              " 'hungry': 3314,\n",
              " 'usually': 6712,\n",
              " 'stops': 6044,\n",
              " 'hella': 3177,\n",
              " 'weed': 6917,\n",
              " 'smoke': 5811,\n",
              " 'awarded': 1101,\n",
              " 'city': 1715,\n",
              " 'break': 1396,\n",
              " '200': 335,\n",
              " 'summer': 6139,\n",
              " 'shopping': 5681,\n",
              " 'spree': 5961,\n",
              " 'wk': 7020,\n",
              " 'store': 6046,\n",
              " '88039': 675,\n",
              " 'skilgme': 5759,\n",
              " 'tscs087147403231winawk': 6562,\n",
              " 'age16': 832,\n",
              " '50perwksub': 528,\n",
              " 'shall': 5635,\n",
              " 'pickle': 4836,\n",
              " 'isn': 3506,\n",
              " 'frnd': 2809,\n",
              " 'necesity': 4407,\n",
              " 'life': 3830,\n",
              " 'imagine': 3376,\n",
              " 'urself': 6697,\n",
              " 'witout': 7017,\n",
              " 'hw': 3328,\n",
              " 'feel': 2620,\n",
              " 'colleg': 1786,\n",
              " 'wth': 7102,\n",
              " 'cell': 1605,\n",
              " 'abt': 742,\n",
              " 'functions': 2833,\n",
              " 'thnk': 6378,\n",
              " 'events': 2491,\n",
              " 'espe': 2474,\n",
              " 'cared': 1553,\n",
              " 'missed': 4215,\n",
              " 'amp': 903,\n",
              " 'irritated': 3496,\n",
              " '4wrd': 517,\n",
              " 'frnds': 2810,\n",
              " 'wthout': 7103,\n",
              " 'live': 3880,\n",
              " 'jst': 3605,\n",
              " 'takecare': 6228,\n",
              " 'goodmorning': 2977,\n",
              " 'brum': 1437,\n",
              " 'thanks': 6337,\n",
              " 'putting': 5126,\n",
              " 'keeping': 3651,\n",
              " 'happy': 3120,\n",
              " 'soon': 5868,\n",
              " 'im': 3373,\n",
              " 'tellmiss': 6291,\n",
              " 'way': 6891,\n",
              " 'bloomberg': 1310,\n",
              " 'message': 4163,\n",
              " 'center': 1607,\n",
              " '447797706009': 482,\n",
              " 'apply': 969,\n",
              " 'future': 2842,\n",
              " 'http': 3298,\n",
              " 'careers': 1555,\n",
              " 'com': 1791,\n",
              " 'enjoy': 2435,\n",
              " 'plural': 4892,\n",
              " 'noun': 4515,\n",
              " 'research': 5331,\n",
              " 'sure': 6165,\n",
              " 'checking': 1656,\n",
              " 'happening': 3114,\n",
              " 'area': 991,\n",
              " 'aight': 850,\n",
              " 'sleeping': 5774,\n",
              " 'surfing': 6168,\n",
              " 'cool': 1888,\n",
              " 'breeze': 1406,\n",
              " 'bright': 1410,\n",
              " 'sun': 6142,\n",
              " 'fresh': 2793,\n",
              " 'flower': 2711,\n",
              " 'twittering': 6588,\n",
              " 'birds': 1270,\n",
              " 'waiting': 6837,\n",
              " 'wish': 7006,\n",
              " 'ringtone': 5389,\n",
              " 'order': 4630,\n",
              " 'reference': 5261,\n",
              " 'number': 4526,\n",
              " 'x49': 7114,\n",
              " 'mobile': 4246,\n",
              " 'charged': 1633,\n",
              " 'tone': 6470,\n",
              " 'arrive': 1016,\n",
              " 'customer': 2002,\n",
              " 'services': 5609,\n",
              " '09065989182': 214,\n",
              " 'colour': 1789,\n",
              " 'red': 5257,\n",
              " 'txtstar': 6598,\n",
              " 'does': 2245,\n",
              " 'uncle': 6626,\n",
              " 'timi': 6420,\n",
              " 'clearing': 1733,\n",
              " 'cars': 1569,\n",
              " 'getting': 2914,\n",
              " 'really': 5219,\n",
              " 'bad': 1128,\n",
              " 'totally': 6498,\n",
              " 'rejected': 5281,\n",
              " 'kinda': 3682,\n",
              " 'thing': 6366,\n",
              " 'sent': 5598,\n",
              " 'prices': 5028,\n",
              " 'mean': 4116,\n",
              " 'hi': 3202,\n",
              " 'darlin': 2038,\n",
              " 'london': 3914,\n",
              " 'smashed': 5801,\n",
              " 'driver': 2314,\n",
              " 'big': 1257,\n",
              " 'dent': 2118,\n",
              " 'missing': 4217,\n",
              " 'took': 6479,\n",
              " 'tablets': 6217,\n",
              " 'reaction': 5205,\n",
              " 'morning': 4289,\n",
              " 'going': 2959,\n",
              " 'intention': 3459,\n",
              " 'run': 5453,\n",
              " 'choose': 1700,\n",
              " 'clean': 1728,\n",
              " 'don': 2266,\n",
              " 'say': 5516,\n",
              " 'visitors': 6791,\n",
              " 'maybe': 4111,\n",
              " 'choice': 1698,\n",
              " 'wanted': 6859,\n",
              " 'embarassed': 2413,\n",
              " 'friend': 2800,\n",
              " 'wants': 6861,\n",
              " 'drop': 2319,\n",
              " 'buy': 1483,\n",
              " 'happened': 3113,\n",
              " 'tried': 6537,\n",
              " 'picking': 4835,\n",
              " 'various': 6735,\n",
              " 'points': 4914,\n",
              " 'yeovil': 7157,\n",
              " 'motor': 4298,\n",
              " 'project': 5064,\n",
              " '12': 266,\n",
              " '30': 412,\n",
              " 'max': 4106,\n",
              " 'easy': 2368,\n",
              " 'test': 6316,\n",
              " 'rd': 5199,\n",
              " 'fret': 2794,\n",
              " 'ovulation': 4673,\n",
              " 'strips': 6066,\n",
              " 'wont': 7048,\n",
              " 'til': 6416,\n",
              " 'march': 4072,\n",
              " 'postal': 4953,\n",
              " 'address': 790,\n",
              " 'alright': 887,\n",
              " 'loyalty': 3970,\n",
              " 'offer': 4560,\n",
              " 'nokia6650': 4485,\n",
              " '10': 244,\n",
              " 'txtauction': 6593,\n",
              " 'word': 7056,\n",
              " 'start': 5993,\n",
              " '81151': 632,\n",
              " '4t': 511,\n",
              " 'ctxt': 1982,\n",
              " 'tc': 6266,\n",
              " 'mtmsg': 4325,\n",
              " 'remember': 5295,\n",
              " 'alex': 873,\n",
              " 'pizza': 4860,\n",
              " 'av': 1084,\n",
              " 'wil': 6982,\n",
              " 'use': 6701,\n",
              " 'ta': 6214,\n",
              " 'urgent': 6688,\n",
              " 'trying': 6558,\n",
              " 'todays': 6454,\n",
              " 'draw': 2301,\n",
              " 'shows': 5701,\n",
              " '800': 617,\n",
              " 'prize': 5043,\n",
              " 'guaranteed': 3048,\n",
              " '09050001808': 158,\n",
              " 'land': 3740,\n",
              " 'claim': 1718,\n",
              " 'm95': 4008,\n",
              " 'valid12hrs': 6727,\n",
              " 'babe': 1119,\n",
              " 'lost': 3939,\n",
              " 'painful': 4690,\n",
              " 'personal': 4795,\n",
              " 'thought': 6384,\n",
              " 'try': 6556,\n",
              " 'everybody': 2492,\n",
              " 'recognises': 5250,\n",
              " 'subscribed': 6105,\n",
              " 'service': 5608,\n",
              " 'days': 2055,\n",
              " '82324': 638,\n",
              " 'helpline': 3185,\n",
              " '08706091795': 83,\n",
              " 'basket': 1164,\n",
              " 'mum': 4336,\n",
              " 'messages': 4165,\n",
              " 'got': 2988,\n",
              " 'actually': 781,\n",
              " 'rest': 5351,\n",
              " 'january': 3541,\n",
              " 'male': 4049,\n",
              " 'sale': 5480,\n",
              " 'hot': 3276,\n",
              " 'gay': 2877,\n",
              " 'cheaper': 1649,\n",
              " '08709222922': 88,\n",
              " 'national': 4391,\n",
              " 'rate': 5187,\n",
              " '5p': 548,\n",
              " 'min': 4187,\n",
              " 'cheap': 1648,\n",
              " '8p': 695,\n",
              " 'peak': 4765,\n",
              " 'texts': 6331,\n",
              " '08712460324': 108,\n",
              " '10p': 254,\n",
              " 'honesty': 3249,\n",
              " 'road': 5399,\n",
              " 'bank': 1146,\n",
              " 'tomorrow': 6469,\n",
              " 'tough': 6502,\n",
              " 'decisions': 2080,\n",
              " 'people': 4776,\n",
              " 'womdarfull': 7039,\n",
              " 'actor': 779,\n",
              " 'congrats': 1847,\n",
              " 'special': 5910,\n",
              " 'cinema': 1713,\n",
              " 'pass': 4731,\n",
              " '09061209465': 180,\n",
              " 'suprman': 6163,\n",
              " 'matrix3': 4101,\n",
              " 'starwars3': 5997,\n",
              " 'bx420': 1493,\n",
              " 'ip4': 3484,\n",
              " '5we': 552,\n",
              " '150pm': 295,\n",
              " 'miss': 4213,\n",
              " 'movie': 4304,\n",
              " 'juz': 3626,\n",
              " 'minute': 4202,\n",
              " 'decision': 2079,\n",
              " 'mah': 4031,\n",
              " 'watch': 6877,\n",
              " 'lar': 3751,\n",
              " 'tot': 6496,\n",
              " 'interested': 3460,\n",
              " 'care': 1551,\n",
              " 'sweet': 6191,\n",
              " 'dreams': 2305,\n",
              " 'ummifying': 6620,\n",
              " 'bye': 1495,\n",
              " 'gud': 3050,\n",
              " 'ni8': 4451,\n",
              " 'slp': 5794,\n",
              " 'swt': 6203,\n",
              " 'muah': 4330,\n",
              " 'youdoing': 7172,\n",
              " 'later': 3762,\n",
              " 'sar': 5495,\n",
              " 'money': 4270,\n",
              " '09050000460': 153,\n",
              " 'j89': 3526,\n",
              " 'po': 4897,\n",
              " 'box245c2150pm': 1364,\n",
              " 'issue': 3508,\n",
              " 'weigh': 6924,\n",
              " 'breathe': 1403,\n",
              " 'easier': 2363,\n",
              " 'regret': 5278,\n",
              " 'gr8': 3000,\n",
              " 'leaving': 3795,\n",
              " 'plans': 4872,\n",
              " 'havent': 3142,\n",
              " 'sir': 5742,\n",
              " 'group': 3034,\n",
              " 'mail': 4034,\n",
              " 'check': 1653,\n",
              " 'hit': 3216,\n",
              " 'cash': 1573,\n",
              " 'girl': 2928,\n",
              " '2004': 338,\n",
              " 'account': 760,\n",
              " 'statement': 5998,\n",
              " '07742676969': 27,\n",
              " '786': 608,\n",
              " 'unredeemed': 6661,\n",
              " 'bonus': 1332,\n",
              " '08719180248': 144,\n",
              " 'identifier': 3355,\n",
              " 'code': 1770,\n",
              " '45239': 489,\n",
              " 'expires': 2538,\n",
              " 'mins': 4200,\n",
              " 'busy': 1479,\n",
              " 'finish': 2670,\n",
              " 'looking': 3924,\n",
              " 'forward': 2761,\n",
              " 'finally': 2663,\n",
              " 'meeting': 4132,\n",
              " 'hmv': 3230,\n",
              " '500': 521,\n",
              " 'pounds': 4965,\n",
              " 'genuine': 2901,\n",
              " 'vouchers': 6808,\n",
              " 'answer': 928,\n",
              " 'questions': 5144,\n",
              " 'play': 4873,\n",
              " 'info': 3425,\n",
              " 'www': 7110,\n",
              " '100percent': 249,\n",
              " 'real': 5210,\n",
              " 'accidentally': 754,\n",
              " 'left': 3798,\n",
              " 'silent': 5726,\n",
              " 'night': 4460,\n",
              " 'didn': 2170,\n",
              " 'ya': 7134,\n",
              " 'tht': 6398,\n",
              " 'incident': 3399,\n",
              " 'good': 2972,\n",
              " 'problem': 5047,\n",
              " 'little': 3879,\n",
              " 'experience': 2534,\n",
              " 'understand': 6633,\n",
              " 'american': 895,\n",
              " 'voice': 6799,\n",
              " 'used': 6702,\n",
              " 'agents': 836,\n",
              " 'booked': 1336,\n",
              " 'things': 6367,\n",
              " 'boston': 1350,\n",
              " 'nyc': 4539,\n",
              " 'experiment': 2535,\n",
              " 'online': 4599,\n",
              " 'transaction': 6515,\n",
              " 'came': 1526,\n",
              " 'hostel': 3274,\n",
              " 'sleep': 5772,\n",
              " 'plz': 4895,\n",
              " 'hrishi': 3295,\n",
              " 'fuuuuck': 2843,\n",
              " 'sleepin': 5773,\n",
              " 'sup': 6150,\n",
              " 'dude': 2337,\n",
              " 'makin': 4045,\n",
              " 'weirdy': 6931,\n",
              " 'brownies': 1433,\n",
              " 'cookies': 1886,\n",
              " 'secret': 5560,\n",
              " 'admirer': 795,\n",
              " 'reveal': 5368,\n",
              " 'thinks': 6372,\n",
              " '09058094599': 175,\n",
              " 'oh': 4573,\n",
              " 'training': 6512,\n",
              " 'manual': 4066,\n",
              " 'tech': 6279,\n",
              " 'process': 5053,\n",
              " 'password': 4737,\n",
              " 'reset': 5337,\n",
              " 'troubleshooting': 6544,\n",
              " 'computerless': 1831,\n",
              " 'oreo': 4633,\n",
              " 'truffles': 6550,\n",
              " 'watching': 6880,\n",
              " 'tv': 6582,\n",
              " 'job': 3580,\n",
              " 'hoping': 3264,\n",
              " 'game': 2858,\n",
              " 'yesterday': 7162,\n",
              " 'touch': 6500,\n",
              " 'pls': 4888,\n",
              " 'fondly': 2725,\n",
              " 'bein': 1220,\n",
              " 'thot': 6382,\n",
              " 'abiola': 732,\n",
              " 'nite': 4470,\n",
              " 'pocay': 4907,\n",
              " 'wocay': 7035,\n",
              " '4eva': 502,\n",
              " 'promise': 5068,\n",
              " 'ring': 5387,\n",
              " '2morrowxxxx': 393,\n",
              " 'yup': 7189,\n",
              " 'thanx': 6342,\n",
              " 'reply': 5321,\n",
              " 'pick': 4833,\n",
              " 'heart': 3162,\n",
              " 'mind': 4190,\n",
              " 'wisdom': 7004,\n",
              " 'eyes': 2555,\n",
              " 'alwys': 891,\n",
              " 'panren': 4700,\n",
              " 'paru': 4729,\n",
              " 'wife': 6978,\n",
              " 'relax': 5286,\n",
              " 'wkend': 7021,\n",
              " 'fun': 2831,\n",
              " 'truly': 6551,\n",
              " 'forget': 2746,\n",
              " 'gbp': 2881,\n",
              " 'sms': 5817,\n",
              " 'approve': 975,\n",
              " 'panalam': 4695,\n",
              " 'posts': 4959,\n",
              " 'paid': 4688,\n",
              " 'commercial': 1804,\n",
              " 'hasbro': 3129,\n",
              " 'august': 1075,\n",
              " 'jump': 3616,\n",
              " 'hoops': 3258,\n",
              " 'shut': 5711,\n",
              " 'omg': 4592,\n",
              " 'dream': 2304,\n",
              " 'kids': 3673,\n",
              " 'boys': 1381,\n",
              " 'pissed': 4855,\n",
              " 'told': 6460,\n",
              " 'mark': 4076,\n",
              " 'changing': 1626,\n",
              " 'diapers': 2164,\n",
              " 'cause': 1588,\n",
              " 'owed': 4676,\n",
              " 'face': 2559,\n",
              " 'ey': 2553,\n",
              " 'calm': 1523,\n",
              " 'downon': 2292,\n",
              " 'theacusations': 6347,\n",
              " 'itxt': 3517,\n",
              " 'iwana': 3520,\n",
              " 'wotu': 7077,\n",
              " 'doin': 2257,\n",
              " 'thew': 6362,\n",
              " 'end': 2422,\n",
              " 'haventcn': 3143,\n",
              " 'ages': 837,\n",
              " 'up4': 6669,\n",
              " 'nething': 4432,\n",
              " 'sat': 5502,\n",
              " 'dramatic': 2299,\n",
              " 'schools': 5528,\n",
              " 'closed': 1742,\n",
              " 'apparently': 961,\n",
              " 'inch': 3397,\n",
              " 'snow': 5832,\n",
              " 'supposed': 6161,\n",
              " 'woke': 7036,\n",
              " 'blur': 1319,\n",
              " 'went': 6940,\n",
              " 'liao': 3821,\n",
              " 'oso': 4645,\n",
              " 'helloooo': 3179,\n",
              " 'wake': 6838,\n",
              " 'welcomes': 6934,\n",
              " 'joy': 3600,\n",
              " 'mrng': 4312,\n",
              " 'jason': 3546,\n",
              " 'says': 5518,\n",
              " 'gonna': 2970,\n",
              " 'mallika': 4051,\n",
              " 'sherawat': 5652,\n",
              " 'url': 6694,\n",
              " 'wa': 6823,\n",
              " 'openin': 4608,\n",
              " 'sentence': 5599,\n",
              " 'formal': 2753,\n",
              " 'fine': 2667,\n",
              " 'tt': 6565,\n",
              " 'eatin': 2371,\n",
              " 'puttin': 5125,\n",
              " 'weight': 6926,\n",
              " 'anythin': 944,\n",
              " 'tyler': 6602,\n",
              " 'minor': 4199,\n",
              " 'crisis': 1960,\n",
              " 'sooner': 5869,\n",
              " 'asap': 1024,\n",
              " 'erm': 2460,\n",
              " 'ill': 3369,\n",
              " '45pm': 490,\n",
              " 'park': 4720,\n",
              " 'treat': 6529,\n",
              " 'pending': 4773,\n",
              " 'respect': 5343,\n",
              " 'mother': 4293,\n",
              " 'mails': 4037,\n",
              " 'alrite': 888,\n",
              " 'hunny': 3316,\n",
              " 'wot': 7076,\n",
              " '2nite': 398,\n",
              " 'didnt': 2171,\n",
              " 'goin': 2958,\n",
              " 'jus': 3622,\n",
              " 'pub': 5101,\n",
              " 'instead': 3453,\n",
              " 'chillin': 1686,\n",
              " 'mo': 4242,\n",
              " 'bedroom': 1206,\n",
              " 'jen': 3559,\n",
              " 'aiyo': 860,\n",
              " 'meh': 4137,\n",
              " 'princess': 5034,\n",
              " 'times': 6419,\n",
              " 'thats': 6346,\n",
              " 'ew': 2507,\n",
              " 'friendship': 2803,\n",
              " 'poem': 4911,\n",
              " 'near': 4405,\n",
              " 'hear': 3158,\n",
              " 'fear': 2613,\n",
              " 'cheer': 1660,\n",
              " 'tear': 6275,\n",
              " 'added': 786,\n",
              " 'list': 3868,\n",
              " 'fullonsms': 2829,\n",
              " 'ignoring': 3363,\n",
              " 'dating': 2049,\n",
              " 'started': 5994,\n",
              " 'sport': 5954,\n",
              " 'radio': 5160,\n",
              " 'connection': 1851,\n",
              " 'coincidence': 1774,\n",
              " 'hook': 3257,\n",
              " 'means': 4120,\n",
              " 'right': 5383,\n",
              " 'valuable': 6728,\n",
              " 'situations': 5752,\n",
              " 'second': 5557,\n",
              " 'loosing': 3930,\n",
              " 'si': 5713,\n",
              " 'como': 1808,\n",
              " 'listened2the': 3871,\n",
              " 'plaid': 4866,\n",
              " 'album': 867,\n",
              " 'gd': 2884,\n",
              " 'air1': 854,\n",
              " 'hilarious': 3207,\n",
              " 'bought': 1354,\n",
              " 'braindance': 1386,\n",
              " 'comp': 1809,\n",
              " 'ofstuff': 4570,\n",
              " 'aphex': 953,\n",
              " 'abel': 728,\n",
              " 'hav2hear': 3139,\n",
              " 'xxxx': 7129,\n",
              " 'wana': 6854,\n",
              " 'praps': 4988,\n",
              " 'meant': 4121,\n",
              " 'goodo': 2981,\n",
              " 'stay': 6001,\n",
              " 'england': 2433,\n",
              " 'official': 4566,\n",
              " 'poly': 4918,\n",
              " 'flag': 2688,\n",
              " 'yer': 7159,\n",
              " '84199': 653,\n",
              " 'opt': 4618,\n",
              " 'eng': 2430,\n",
              " 'box39822': 1369,\n",
              " 'w111wx': 6814,\n",
              " 'honeybee': 3251,\n",
              " 'said': 5475,\n",
              " 'sweetest': 6192,\n",
              " 'world': 7065,\n",
              " 'god': 2954,\n",
              " 'laughed': 3767,\n",
              " 'havnt': 3147,\n",
              " 'met': 4170,\n",
              " 'person': 4794,\n",
              " 'reading': 5208,\n",
              " 'moral': 4285,\n",
              " 'crack': 1934,\n",
              " 'jokes': 3590,\n",
              " 'gm': 2943,\n",
              " 'gn': 2945,\n",
              " 'ge': 2886,\n",
              " 'study': 6082,\n",
              " 'tap': 6247,\n",
              " 'spile': 5931,\n",
              " 'seven': 5616,\n",
              " 'gas': 2870,\n",
              " 'broad': 1422,\n",
              " 'canal': 1530,\n",
              " 'wan2': 6853,\n",
              " 'greet': 3023,\n",
              " 'westlife': 6950,\n",
              " 'm8': 4006,\n",
              " 'currently': 1997,\n",
              " 'tour': 6503,\n",
              " 'unbreakable': 6625,\n",
              " 'untamed': 6667,\n",
              " 'unkempt': 6652,\n",
              " '83049': 640,\n",
              " 'cost': 1903,\n",
              " '50p': 526,\n",
              " 'std': 6006,\n",
              " 'drunk': 2326,\n",
              " 'motherfucker': 4294,\n",
              " 'textbuddy': 6324,\n",
              " 'horny': 3266,\n",
              " 'guys': 3068,\n",
              " '25p': 362,\n",
              " 'receive': 5237,\n",
              " 'search': 5552,\n",
              " 'postcode': 4955,\n",
              " 'gaytextbuddy': 2880,\n",
              " '89693': 690,\n",
              " '08715500022': 122,\n",
              " 'rpl': 5434,\n",
              " 'cnl': 1759,\n",
              " 'hiya': 3220,\n",
              " 'weekend': 6920,\n",
              " 'usual': 6711,\n",
              " 'ard': 990,\n",
              " 'smth': 5821,\n",
              " 'doc': 2239,\n",
              " 'gave': 2876,\n",
              " 'pain': 4689,\n",
              " 'meds': 4128,\n",
              " 'mahal': 4032,\n",
              " 'bus': 1473,\n",
              " 'decimal': 2078,\n",
              " 'cooking': 1887,\n",
              " 'oops': 4604,\n",
              " 'tomo': 6467,\n",
              " 'station': 5999,\n",
              " 'dhoni': 2157,\n",
              " 'luck': 3978,\n",
              " 'title': 6433,\n",
              " 'waking': 6839,\n",
              " 'afternoon': 828,\n",
              " 'church': 1710,\n",
              " 'holla': 3240,\n",
              " 'let': 3815,\n",
              " 'salad': 5477,\n",
              " 'desert': 2132,\n",
              " 'beers': 1210,\n",
              " 'news': 4447,\n",
              " 'freefone': 2784,\n",
              " '08006344447': 56,\n",
              " '1000': 246,\n",
              " '2000': 336,\n",
              " 'speak': 5908,\n",
              " 'operator': 4612,\n",
              " 'hr': 3294,\n",
              " 'trip': 6538,\n",
              " 'audition': 1072,\n",
              " 'wednesday': 6914,\n",
              " 'whats': 6955,\n",
              " 'printed': 5036,\n",
              " 'upstairs': 6682,\n",
              " 'wasnt': 6872,\n",
              " 'phoned': 4821,\n",
              " 'voda': 6796,\n",
              " 'numbers': 4527,\n",
              " 'ending': 2424,\n",
              " '1225': 270,\n",
              " 'selected': 5579,\n",
              " '50award': 523,\n",
              " 'match': 4094,\n",
              " '08712300220': 95,\n",
              " 'quoting': 5155,\n",
              " '3100': 424,\n",
              " 'standard': 5984,\n",
              " 'rates': 5188,\n",
              " 'app': 960,\n",
              " 'today': 6453,\n",
              " 'accept': 749,\n",
              " 'brother': 1429,\n",
              " 'lover': 3958,\n",
              " 'dear1': 2067,\n",
              " 'best1': 1238,\n",
              " 'clos1': 1740,\n",
              " 'lvblefrnd': 3993,\n",
              " 'jstfrnd': 3606,\n",
              " 'cutefrnd': 2007,\n",
              " 'lifpartnr': 3833,\n",
              " 'belovd': 1228,\n",
              " 'swtheart': 6204,\n",
              " 'bstfrnd': 1442,\n",
              " 'rply': 5435,\n",
              " 'enemy': 2428,\n",
              " 'bloo': 1307,\n",
              " 'bowl': 1358,\n",
              " 'urgnt': 6691,\n",
              " 'wating': 6885,\n",
              " 'difficult': 2181,\n",
              " 'girls': 2931,\n",
              " 'companion': 1811,\n",
              " 'chef': 1666,\n",
              " 'listener': 3872,\n",
              " 'organizer': 4636,\n",
              " 'boyfriend': 1380,\n",
              " 'sympathetic': 6207,\n",
              " 'athletic': 1054,\n",
              " 'warm': 6864,\n",
              " 'courageous': 1919,\n",
              " 'determined': 2145,\n",
              " 'true': 6548,\n",
              " 'dependable': 2125,\n",
              " 'intelligent': 3457,\n",
              " 'psychologist': 5098,\n",
              " 'pest': 4802,\n",
              " 'exterminator': 2550,\n",
              " 'psychiatrist': 5096,\n",
              " 'healer': 3156,\n",
              " 'stylist': 6094,\n",
              " 'aaniye': 722,\n",
              " 'pudunga': 5105,\n",
              " 'venaam': 6749,\n",
              " 'request': 5326,\n",
              " 'maangalyam': 4011,\n",
              " 'alaipayuthe': 866,\n",
              " 'set': 5611,\n",
              " 'callertune': 1516,\n",
              " 'callers': 1515,\n",
              " 'press': 5017,\n",
              " 'copy': 1893,\n",
              " 'friends': 2801,\n",
              " 'tirunelvai': 6428,\n",
              " 'lick': 3825,\n",
              " 'pussy': 5123,\n",
              " 'inside': 3447,\n",
              " 'office': 4564,\n",
              " 'filling': 2654,\n",
              " 'forms': 2757,\n",
              " 'textin': 6327,\n",
              " 'bout': 1356,\n",
              " 'worries': 7069,\n",
              " 'photo': 4824,\n",
              " 'shoot': 5678,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#check count of words in your features (Hint: Use vocabulary_ on CountVectorizer)\n",
        "vect.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Tn5A5sluVV1t",
        "outputId": "fb6ecfce-3b29-4940-d31c-a78fd8dd1c07",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['00', '000', '008704050406', ..., 'zyada', 'èn', '〨ud'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#Check how feature names separately in form of words( Hint: Use get_feature_names function on  CountVectorizer)\n",
        "vect.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqYNGStGVV1t"
      },
      "source": [
        "Now let's transform our training features.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "SjhenI-rVV1t"
      },
      "outputs": [],
      "source": [
        "# transform feature data\n",
        "X_train_transformed = vect.transform(X_train)\n",
        "X_test_tranformed = vect.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "qG93AGt1VV1t",
        "outputId": "045d3d9e-09fe-4764-dca5-ef776f4ed44b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#Now let's see how our X_train data looks like after tranformation ( hint: convert it into array and then print )\n",
        "print(X_train_transformed.toarray())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "q4ijNhWXVV1u",
        "outputId": "74c0fe9d-b164-491d-e95f-78964824e6e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7204\n"
          ]
        }
      ],
      "source": [
        "# printing length of feature names\n",
        "print(len(vect.get_feature_names_out()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxO77ITgVV1u"
      },
      "source": [
        "So our final dictionary is made of 7204 words (after discarding the stop words). Now, to do classification, we need to represent all the documents with respect to these words in the form of features.\n",
        "\n",
        "Every document will be converted into a *feature vector* representing presence of these words in that document. Let's convert each of our training documents in to a feature vector.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "THrsV94PVV1u",
        "outputId": "c0473f23-105f-4dde-ea7e-cf4a3df15eb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4179, 7204)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Print shape of X_train_transformed\n",
        "X_train_transformed.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxmMhb7mVV1-"
      },
      "source": [
        "You can see X_tranformed is a 4179 x 7456 sparse matrix. It has 4179 rows for each of our 4179 documents and 7456 columns each\n",
        "for number of words of the dictionary which we just created. Let us print X_transformed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "UdUV_J24VV1-",
        "outputId": "2b12d415-4d79-46d5-e2f2-a5c6c70402fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 50)\t1\n",
            "  (0, 264)\t1\n",
            "  (0, 509)\t1\n",
            "  (0, 1527)\t1\n",
            "  (0, 1971)\t1\n",
            "  (0, 2780)\t2\n",
            "  (0, 3089)\t1\n",
            "  (0, 3763)\t1\n",
            "  (0, 3852)\t1\n",
            "  (0, 4248)\t1\n",
            "  (0, 4624)\t1\n",
            "  (0, 4626)\t1\n",
            "  (0, 4818)\t1\n",
            "  (0, 4822)\t1\n",
            "  (0, 5027)\t1\n",
            "  (0, 5310)\t1\n",
            "  (0, 6673)\t1\n",
            "  (1, 2169)\t1\n",
            "  (1, 6028)\t1\n",
            "  (1, 6545)\t1\n",
            "  (2, 98)\t1\n",
            "  (2, 563)\t1\n",
            "  (2, 1867)\t1\n",
            "  (2, 2436)\t1\n",
            "  (2, 3180)\t1\n",
            "  :\t:\n",
            "  (4176, 3879)\t1\n",
            "  (4176, 4417)\t1\n",
            "  (4176, 5229)\t1\n",
            "  (4176, 6191)\t1\n",
            "  (4176, 7134)\t1\n",
            "  (4177, 254)\t1\n",
            "  (4177, 307)\t1\n",
            "  (4177, 358)\t1\n",
            "  (4177, 831)\t1\n",
            "  (4177, 2046)\t1\n",
            "  (4177, 2704)\t1\n",
            "  (4177, 3585)\t1\n",
            "  (4177, 3623)\t1\n",
            "  (4177, 4130)\t1\n",
            "  (4177, 4315)\t1\n",
            "  (4177, 4771)\t1\n",
            "  (4177, 5234)\t1\n",
            "  (4177, 5321)\t1\n",
            "  (4177, 5487)\t1\n",
            "  (4177, 5620)\t1\n",
            "  (4177, 6321)\t1\n",
            "  (4177, 6374)\t1\n",
            "  (4177, 6453)\t1\n",
            "  (4178, 1643)\t1\n",
            "  (4178, 5817)\t1\n"
          ]
        }
      ],
      "source": [
        "#Print X_train_transformed\n",
        "print(X_train_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrs-ohizVV1_"
      },
      "source": [
        "This representation can be understood as follows:\n",
        "\n",
        "Consider first 4 rows of the output: (0,50), (0,264), (0,509) and (0,1552). It says that the first document (index 0) has\n",
        "50th , 264nd , 509th and 1552th 'word' present in the document, and that they appear only\n",
        "once/twice in the document- indicated by the right hand column entry.\n",
        "\n",
        "\n",
        "\n",
        "In real problems, you often work with large documents and vocabularies, and each document contains only a few words in the vocabulary. So it would be a waste of space to store the vocabulary in a typical dataframe, since most entries would be zero. Also, matrix products, additions etc. are much faster with sparse matrices. That's why we use sparse matrices to store the data.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kQcvU8gxVV1_",
        "outputId": "8b1b49ca-b70a-4725-dad9-ee8dee8963e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['00' '000' '008704050406' ... 'zyada' 'èn' '〨ud']\n"
          ]
        }
      ],
      "source": [
        "#Print feature names\n",
        "print(vect.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "CRxuxmIPVV1_",
        "outputId": "3ff313f9-3283-48f4-f528-c702dc6eecc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      00  000  008704050406  0121  01223585236  01223585334  0125698789  02  \\\n",
              "0      0    0             0     0            0            0           0   0   \n",
              "1      0    0             0     0            0            0           0   0   \n",
              "2      0    0             0     0            0            0           0   0   \n",
              "3      0    0             0     0            0            1           0   0   \n",
              "4      0    0             0     0            0            0           0   0   \n",
              "...   ..  ...           ...   ...          ...          ...         ...  ..   \n",
              "4174   0    0             0     0            0            0           0   0   \n",
              "4175   0    0             0     0            0            0           0   0   \n",
              "4176   0    0             0     0            0            0           0   0   \n",
              "4177   0    0             0     0            0            0           0   0   \n",
              "4178   0    0             0     0            0            0           0   0   \n",
              "\n",
              "      0207  02072069400  ...  zed  zeros  zhong  zindgi  zoe  zoom  zouk  \\\n",
              "0        0            0  ...    0      0      0       0    0     0     0   \n",
              "1        0            0  ...    0      0      0       0    0     0     0   \n",
              "2        0            0  ...    0      0      0       0    0     0     0   \n",
              "3        0            0  ...    0      0      0       0    0     0     0   \n",
              "4        0            0  ...    0      0      0       0    0     0     0   \n",
              "...    ...          ...  ...  ...    ...    ...     ...  ...   ...   ...   \n",
              "4174     0            0  ...    0      0      0       0    0     0     0   \n",
              "4175     0            0  ...    0      0      0       0    0     0     0   \n",
              "4176     0            0  ...    0      0      0       0    0     0     0   \n",
              "4177     0            0  ...    0      0      0       0    0     0     0   \n",
              "4178     0            0  ...    0      0      0       0    0     0     0   \n",
              "\n",
              "      zyada  èn  〨ud  \n",
              "0         0   0    0  \n",
              "1         0   0    0  \n",
              "2         0   0    0  \n",
              "3         0   0    0  \n",
              "4         0   0    0  \n",
              "...     ...  ..  ...  \n",
              "4174      0   0    0  \n",
              "4175      0   0    0  \n",
              "4176      0   0    0  \n",
              "4177      0   0    0  \n",
              "4178      0   0    0  \n",
              "\n",
              "[4179 rows x 7204 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-752e0a40-9fd6-4dec-b491-bed3f940947f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>00</th>\n",
              "      <th>000</th>\n",
              "      <th>008704050406</th>\n",
              "      <th>0121</th>\n",
              "      <th>01223585236</th>\n",
              "      <th>01223585334</th>\n",
              "      <th>0125698789</th>\n",
              "      <th>02</th>\n",
              "      <th>0207</th>\n",
              "      <th>02072069400</th>\n",
              "      <th>...</th>\n",
              "      <th>zed</th>\n",
              "      <th>zeros</th>\n",
              "      <th>zhong</th>\n",
              "      <th>zindgi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zouk</th>\n",
              "      <th>zyada</th>\n",
              "      <th>èn</th>\n",
              "      <th>〨ud</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4176</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4177</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4178</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4179 rows × 7204 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-752e0a40-9fd6-4dec-b491-bed3f940947f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-752e0a40-9fd6-4dec-b491-bed3f940947f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-752e0a40-9fd6-4dec-b491-bed3f940947f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4f0f401c-c13d-44c5-bada-208d0c025f87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f0f401c-c13d-44c5-bada-208d0c025f87')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4f0f401c-c13d-44c5-bada-208d0c025f87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "'''converting X_train_transformed matrix to dataframe (Hint:X_train_transformed\n",
        "should be in an array form and columns as vector's feature name )'''\n",
        "\n",
        "pd.DataFrame(X_train_transformed.toarray(),columns=vect.get_feature_names_out())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl7gGxKlVV1_"
      },
      "source": [
        "This table shows how many times a particular word occurs in document. In other words, this is a frequency table of the words.\n",
        "A corpus of documents can thus be represented by a matrix with one row per document and one column per\n",
        "token (e.g. word) occurring in the corpus.\n",
        "\n",
        "We call vectorization the general process of turning a collection of text documents into numerical feature vectors. This specific strategy (tokenization, counting and normalization) is called the \"Bag of Words\" representation. Documents are described by word occurrences while completely ignoring the relative position information of the words in the document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56SiePUBVV1_"
      },
      "source": [
        "#### So, the 4 steps for vectorization are as follows\n",
        "\n",
        "- Import\n",
        "- Instantiate\n",
        "- Fit\n",
        "- Transform\n",
        "\n",
        "Let us summarise all we have done till now:\n",
        "\n",
        "- ```vect.fit(train)``` learns the vocabulary of the training data\n",
        "- ```vect.transform(train)``` uses the fitted vocabulary to build a document-term matrix from the training data\n",
        "- ```vect.transform(test)``` uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdFpOqeKVV2A"
      },
      "source": [
        "## Applying Naive Bayes algorithm\n",
        "\n",
        "Wohoo! so now you can see how your textual features are converted into feature vectors which are in numeric form. Alright, now you training data is ready to be fed into your algorithm\n",
        "\n",
        "We will try using Bernoulli Naive Bayes algorithm first\n",
        "\n",
        "Reference doc: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.BernoulliNB.html\n",
        "\n",
        "\n",
        "### 1. Bernoulli Naive Bayes\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n",
        "\n",
        "\n",
        "Reference video on working of bernoulli Naive Bayes:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 3: Bernoulli Naive Bayes`**"
      ],
      "metadata": {
        "id": "yW1qTPIGnVaY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5TVbAvxiVV2A",
        "outputId": "2dc12071-b7b2-4329-9236-1a766fae9206",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9770279971284996\n"
          ]
        }
      ],
      "source": [
        "#import BernoulliNB\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "\n",
        "# instantiate bernoulli NB object\n",
        "bnb = BernoulliNB()\n",
        "\n",
        "# fit model on training dataset\n",
        "bnb.fit(X_train_transformed,y_train)\n",
        "# predict class of y\n",
        "y_pred_class = bnb.predict(X_test_tranformed)\n",
        "\n",
        "# predict probability on y\n",
        "y_pred_proba = bnb.predict_proba(X_test_tranformed)\n",
        "\n",
        "\n",
        "# print accuracy score\n",
        "print(sklearn.metrics.accuracy_score(y_test,y_pred_class))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1K8PjrVVV2A"
      },
      "source": [
        "### Classification metrics\n",
        "\n",
        "Reference video:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 4 : Confusion Matrix`**"
      ],
      "metadata": {
        "id": "yi4f9X8Cng7O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "iQq_T8cwVV2A",
        "outputId": "07215dfc-ce00-455a-9735-8c5497e8c026",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1207    1]\n",
            " [  31  154]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# get confusion metrics\n",
        "confusion = confusion_matrix(y_test,y_pred_class)\n",
        "#print confusion metrics\n",
        "print(confusion)\n",
        "#Get True negative, Flase positive, Flase negative and True positive using confusion metrics\n",
        "TN = confusion[0,0]\n",
        "FP = confusion[0,1]\n",
        "FN = confusion[1,0]\n",
        "TP = confusion[1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOhhGFGEVV2A"
      },
      "source": [
        "TO know what exactly specificity and sensitivity are, then do watch this video :\n",
        "\n",
        "We hope by watching this small video you got your big doubts cleared!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 5 : sensitivity & specificity`**"
      ],
      "metadata": {
        "id": "Q6abmuQinsvk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NUqJRnBOVV2A",
        "outputId": "915d15d3-22a4-43f0-fe62-0efbd53d81b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8324324324324325\n"
          ]
        }
      ],
      "source": [
        "# Calculate sensitivity using confusion metrics\n",
        "sensitivity = TP/float(FN+TP)\n",
        "\n",
        "#Print sensitivity\n",
        "print(sensitivity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "I6JDxQS2VV2B",
        "outputId": "25166cb3-e9b5-42c5-9ed5-50e215186900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9991721854304636\n"
          ]
        }
      ],
      "source": [
        "# Calculate specificity using confusion metrics\n",
        "specificity = TN/float(TN+FP)\n",
        "#Print specificity\n",
        "print(specificity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "UpCabnloVV2B",
        "outputId": "55877c90-5536-4d17-a4fe-70a63b838e01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9935483870967742\n"
          ]
        }
      ],
      "source": [
        "# Calculate precision using confusion metrics\n",
        "precision = TP/float(TP+FP)\n",
        "\n",
        "# print precision\n",
        "print(precision)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apt9V0czVV2B"
      },
      "source": [
        "Let us print precision, recall and f1 score  using metrics sklearn library classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "6aunfrsYVV2B",
        "outputId": "caa166ad-0c6a-4abd-c031-6080589196b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      1208\n",
            "           1       0.99      0.83      0.91       185\n",
            "\n",
            "    accuracy                           0.98      1393\n",
            "   macro avg       0.98      0.92      0.95      1393\n",
            "weighted avg       0.98      0.98      0.98      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#Print Precision, recall, f1-score and support\n",
        "print(classification_report(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPDdLCLKVV2B"
      },
      "source": [
        "Well done! we hope you remember what are these data science terminologies( precision, recall and f1-score) mean.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKJq2z1sVV2B"
      },
      "source": [
        "## Creating ROC curve\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n",
        "\n",
        "\n",
        "AUC - ROC curve is a performance measurement for the classification problems at various threshold settings. It tells how much the model is capable of distinguishing between classes. Higher the AUC, the better the model is at predicting 0 classes as 0 and 1 classes as 1\n",
        "\n",
        "Reference video:\n",
        "Reference doc: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 6: ROC AUC.`**"
      ],
      "metadata": {
        "id": "f2-r4nz9n4dD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Fp0GV8fXVV2B"
      },
      "outputs": [],
      "source": [
        "# import roc_curve and and auc\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "\n",
        "#Calculate false_positive_rate , true_positive_rate and thresholds using roc_curve\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
        "\n",
        "\n",
        "\n",
        "#Calculate area under curve\n",
        "roc_auc = auc(false_positive_rate,true_positive_rate)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "IjECj7wQVV2C",
        "outputId": "d3fa7f9d-8756-43a0-edc2-35d99381d100",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9967692858421334\n"
          ]
        }
      ],
      "source": [
        "#Print area under the curve\n",
        "\n",
        "print(roc_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kkcXe-xVV2C"
      },
      "source": [
        "The ROC curve is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lygo6UkJVV2C",
        "outputId": "d79076be-94b0-47c6-dfe1-928afcb68080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plotting the ROC curve (false_positive_rate vs true_positive_rate)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TCdBksWVV2C"
      },
      "source": [
        "From above plot what do you understand?\n",
        "\n",
        "Do comment below on the same!"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "dwvtJ4lFVV2C"
      },
      "source": [
        "#comment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zYlBiLxVV2C"
      },
      "source": [
        "Good job so far!\n",
        "\n",
        "Now we will try out Multinomial Naive Bayes to solve this use case. SO let's get started.\n",
        "\n",
        "Reference doc :<a href= \"https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#:~:text=The%20multinomial%20Naive%20Bayes%20classifier,tf%2Didf%20may%20also%20work\">sklearn document </a>\n",
        "\n",
        "### 2. Multinomial Naive Bayes\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 7 : Multinomial Naive bayes`**"
      ],
      "metadata": {
        "id": "CysICqFQoEFi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "eadXLUgvVV2D",
        "outputId": "e70ad569-d01e-4b6e-ecad-a9b4aa546b9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9877961234745154\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# import MultinomialNB\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# instantiate bernoulli NB object\n",
        "mnb = MultinomialNB()\n",
        "\n",
        "# fit model on training dataset\n",
        "mnb.fit(X_train_transformed,y_train)\n",
        "# predict class of y\n",
        "y_pred_class =mnb.predict(X_test_tranformed)\n",
        "\n",
        "# predict probability on y\n",
        "y_pred_proba =mnb.predict_proba(X_test_tranformed)\n",
        "\n",
        "# print accuracy score\n",
        "print(accuracy_score(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ35VFKaVV2D"
      },
      "source": [
        "#### Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Vbjt3CU6VV2D",
        "outputId": "8db1c592-5bf5-431f-baa9-6f62d8c61825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1201    7]\n",
            " [  10  175]]\n"
          ]
        }
      ],
      "source": [
        "# get confusion metrics\n",
        "confusion = confusion_matrix(y_test,y_pred_class)\n",
        "\n",
        "#print confusion metrics\n",
        "print(confusion)\n",
        "#Get True negative, Flase positive, Flase negative and True positive using confusion metrics\n",
        "TN = confusion[0,0]\n",
        "FP = confusion[0,1]\n",
        "FN = confusion[1,0]\n",
        "TP = confusion[1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1d3I83qVV2D"
      },
      "source": [
        "Let us print precision, recall and f1 score  using metrics sklearn library classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "cVZkMjw-VV2D",
        "outputId": "3b622d09-678a-4fbe-d86f-a194f405317b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99      1208\n",
            "           1       0.96      0.95      0.95       185\n",
            "\n",
            "    accuracy                           0.99      1393\n",
            "   macro avg       0.98      0.97      0.97      1393\n",
            "weighted avg       0.99      0.99      0.99      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import classification_report\n",
        "\n",
        "\n",
        "#Print Precision, recall, f1-score and support\n",
        "print(classification_report(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgRz4eNiVV2D"
      },
      "source": [
        "#### ROC curve\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "aeHtG_VeVV2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7559ac3-e7b0-4031-c72a-120c4600b264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9921872203329157\n"
          ]
        }
      ],
      "source": [
        "# import roc_curve and and auc\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "\n",
        "#Calculate false_positive_rate , true_positive_rate and thresholds using roc_curve\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
        "\n",
        "\n",
        "\n",
        "#Calculate area under curve\n",
        "roc_auc = auc(false_positive_rate,true_positive_rate)\n",
        "print(roc_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDeQ1cQwVV2E"
      },
      "source": [
        "The ROC curve is plotted with TPR against the FPR where TPR is on the y-axis and FPR is on the x-axis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "pLxbo4B9VV2E",
        "outputId": "997ac6fb-1ef7-4b5c-e8e3-7c705406cb28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plotting the ROC curve (false_positive_rate vs true_positive_rate)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1EQAAA2VV2E"
      },
      "source": [
        "Do comment on above on the plot!"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "QevE2J3jVV2E"
      },
      "source": [
        "#comment:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPWZikb7VV2E"
      },
      "source": [
        "Though guassian naive bayes is applicable in this case, but still we try to implement guassian Niave Bayes as well here and see how differently it performs form the ohter two variant we already saw.\n",
        "\n",
        "Reference doc: https://scikit-learn.org/stable/modules/naive_bayes.html#gaussian-naive-bayes\n",
        "\n",
        "### 3. Guassian Naive Bayes\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n",
        "\n",
        "\n",
        "Reference video: https://www.youtube.com/watch?v=H3EjCKtlVog"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **`Watch Video 8: Gaussian Naive bayes`**"
      ],
      "metadata": {
        "id": "dFybb63ooSLo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "zc0U4_SQVV2E",
        "outputId": "8e8da48c-0432-4686-a4be-679b03b21233",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8901651112706389\n"
          ]
        }
      ],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Instantiate Gaussian NB object\n",
        "gnb = GaussianNB()\n",
        "\n",
        "# Convert sparse matrices to dense arrays\n",
        "X_train_dense = X_train_transformed.toarray()\n",
        "X_test_dense = X_test_tranformed.toarray()\n",
        "\n",
        "# Fit model on training dataset\n",
        "gnb.fit(X_train_dense, y_train)\n",
        "\n",
        "# Predict class labels\n",
        "y_pred_class = gnb.predict(X_test_dense)\n",
        "y_pred_proba =gnb.predict_proba(X_test_dense)\n",
        "# Print accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred_class)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qce21FglVV2E"
      },
      "source": [
        "Note: If you get an error while doing above cell then just try to understand the code and try to change the code accordingly.\n",
        "\n",
        "#### Evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "JpTv7FB_VV2E",
        "outputId": "fd754119-8934-47db-c3b4-c037e6820848",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1066  142]\n",
            " [  11  174]]\n"
          ]
        }
      ],
      "source": [
        "# get confusion metrics\n",
        "confusion = confusion_matrix(y_test,y_pred_class)\n",
        "\n",
        "#print confusion metrics\n",
        "print(confusion)\n",
        "#Get True negative, Flase positive, Flase negative and True positive using confusion metrics\n",
        "TN = confusion[0,0]\n",
        "FP = confusion[0,1]\n",
        "FN = confusion[1,0]\n",
        "TP = confusion[1,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVYh2a_6VV2F"
      },
      "source": [
        "Let us print precision, recall and f1 score  using metrics sklearn library classification report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "9P-4D5gEVV2F",
        "outputId": "d3ac0bf8-5dce-40c3-fffc-374c149a3923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.88      0.93      1208\n",
            "           1       0.55      0.94      0.69       185\n",
            "\n",
            "    accuracy                           0.89      1393\n",
            "   macro avg       0.77      0.91      0.81      1393\n",
            "weighted avg       0.93      0.89      0.90      1393\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#import classification_report\n",
        "\n",
        "\n",
        "#Print Precision, recall, f1-score and support\n",
        "print(classification_report(y_test,y_pred_class))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svDmk0syVV2F"
      },
      "source": [
        "####  ROC Curve\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "EijEfsgEVV2F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81563ebc-3394-4944-ecf2-b46400a24c2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9114954358331843\n"
          ]
        }
      ],
      "source": [
        "# import roc_curve and and auc\n",
        "from sklearn.metrics import roc_curve,auc\n",
        "\n",
        "#Calculate false_positive_rate , true_positive_rate and thresholds using roc_curve\n",
        "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_proba[:,1])\n",
        "\n",
        "\n",
        "\n",
        "#Calculate area under curve\n",
        "roc_auc = auc(false_positive_rate,true_positive_rate)\n",
        "print(roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "7KY__0cFVV2F",
        "outputId": "ab52ca37-39ec-4b8e-cbf2-4b1d94070db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# plotting the ROC curve (false_positive_rate vs true_positive_rate)\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(false_positive_rate, true_positive_rate)\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHa96vU_VV2F"
      },
      "source": [
        "Do comment on above on the plot!\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "HqU3jkGPVV2F"
      },
      "source": [
        "#comment:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pctIEoMSVV2F"
      },
      "source": [
        "If you will see all three variant result of Naive Bayes, performance of multinomial is better than the other two variant.\n",
        "\n",
        "Let's print accuracy of all three below:\n",
        "\n",
        "\n",
        "<p style='text-align: right;'> 10 points </p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "0LRizzjzVV2F",
        "outputId": "d846940d-df63-4b1c-a0e2-cfc9514cf203",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli : 0.9770279971284996\n",
            "Multinomial : 0.9877961234745154\n",
            "Gaussian : 0.8901651112706389\n"
          ]
        }
      ],
      "source": [
        "# print accuracy score of all three Naive Bayes algorithms.\n",
        "print(\"Bernoulli :\",accuracy_score(y_test,bnb.predict(X_test_tranformed.toarray())))\n",
        "print(\"Multinomial :\",accuracy_score(y_test,mnb.predict(X_test_tranformed.toarray())))\n",
        "print(\"Gaussian :\",accuracy_score(y_test,gnb.predict(X_test_tranformed.toarray())))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s25CxjavVV2G"
      },
      "source": [
        "And hence it's proved that Multinomial Naive Bayes would solve this usecase of classifying spam messages correctly.\n",
        "\n",
        "So here with this conclusion that Multinomial works better here because frequency of each feature word has occured more than once in many cases, and hence multinomial fits  better in this case compared to Bernoulli and guassian Naive Bayes\n",
        "\n",
        "So well Done.\n",
        "\n",
        "\n",
        "**Note:** Please do watch all the videos provided in assignments, as it's purpose is to give clarity on each topic to get basics right inorder to crack any data science interview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE8u_sZlVV2G"
      },
      "source": [
        "---------------------------------\n",
        "\n",
        "# Cheers:) you have completed the 17th milestone challenge too.\n",
        "\n",
        "--------------------------------\n",
        "\n",
        "# FeedBack Time\n",
        "We hope you’ve enjoyed this course so far. We’re committed to help you use \"AI for All\" course to its full potential, so that you have a great learning experience. And that’s why we need your help in form of a feedback here.\n",
        "\n",
        "Please fill this feedback form https://docs.google.com/forms/d/e/1FAIpQLSfjBmH0yJSSA34IhSVx4h2eDMgOAeG4Dk-yHid__NMTk3Hq5g/viewform"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "56SiePUBVV1_"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}